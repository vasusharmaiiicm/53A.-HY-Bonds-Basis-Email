{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce2cd38-5649-4144-a450-6df13cf31d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_update_live = True\n",
    "email_both = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06c55c96-14f7-47ba-b243-74810b410cf4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from pydataquery import DataQuery\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from xbbg import blp\n",
    "import numpy as np\n",
    "import pytz\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import statsmodels.api as sm\n",
    "from ipywidgets import interact, Dropdown, HBox, VBox, Button, Output, Text, widgets\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import re\n",
    "import scipy.stats as stats\n",
    "from adjustText import adjust_text\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import sympy as sp\n",
    "import itertools\n",
    "import warnings\n",
    "import openpyxl\n",
    "import subprocess\n",
    "import dataframe_image as dfi\n",
    "import time\n",
    "import pyautogui\n",
    "import pygetwindow as gw\n",
    "import pyodbc\n",
    "import ast\n",
    "import json\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0e2f76b-30df-4ecb-ab20-d2835163e2ba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dft = pd.read_excel(\"DQ_Data_v75.xlsx\")\n",
    "dft.set_index(dft.columns[0],inplace=True)\n",
    "dft.index.name = None\n",
    "dft.index = pd.to_datetime(dft.index, format='%Y-%m-%d').date\n",
    "df_back = dft.copy()\n",
    "\n",
    "start_date = df_back.index.max()\n",
    "\n",
    "##################  Change here only\n",
    "\n",
    "isin_list = [\"US105756BX78\", \"US105756BZ27\", \"US105756CA66\", \"US105756CC23\", \"US105756CG37\", \"US105756CE88\", \"US105756CK49\", \"US105756CF53\", \"US105756CH10\", \"US105756BW95\", \"US105756BY51\", \"US105756CB40\", \"US105756CJ75\", \"US168863DX33\", \"US168863CF36\", \"US168863EB04\", \"US168863DP09\", \"US168863DN50\", \"US168863DT21\", \"US168863DV76\", \"US168863DZ80\", \"US168863DS48\", \"US168863DY16\", \"US168863CE60\", \"US168863DL94\", \"US168863DW59\", \"XS2327851874\", \"US168863EA21\", \"US168863DQ81\", \"US168863DU93\", \"US195325CX13\", \"US195325DL65\", \"US195325DP79\", \"US195325DR36\", \"US195325DS19\", \"US195325DZ51\", \"US195325EF88\", \"US195325EG61\", \"US195325EL56\", \"US195325BK01\", \"US195325BM66\", \"US195325EA91\", \"US195325BR53\", \"US195325CU73\", \"US195325DQ52\", \"US195325DT91\", \"US195325EM30\", \"US195325DX04\", \"US91086QBG29\", \"US91087BAC46\", \"US91087BAE02\", \"US91087BAU44\", \"US91087BAF76\", \"US91087BAY65\", \"US91087BAH33\", \"US91087BAM28\", \"US91087BAK61\", \"US91087BAT70\", \"US91087BAR15\", \"US91087BAV27\", \"US91087BAZ31\", \"US91086QAV05\", \"US91087BAQ32\", \"US91086QBB32\", \"US91086QBE70\", \"US91086QBF46\", \"US91087BAB62\", \"US91087BAD29\", \"US91087BAG59\", \"US91087BAL45\", \"US91087BAS97\", \"US91087BAX82\", \"US91087BBA70\", \"US91087BAN01\", \"XS2280637039\", \"US91086QAZ19\", \"USP90603AN40\", \"US698299BF03\", \"US698299BK97\", \"US698299BX19\", \"USP90603AP97\", \"US698299BN37\", \"US698299BR41\", \"US698299BT07\", \"US698299AW45\", \"US698299BW36\", \"US698299BY91\", \"US698299BG85\", \"US698299BH68\", \"US698299BB98\", \"US698299BV52\", \"US698299BM53\", \"US698299BL70\", \"US698299BS24\", \"US715638DE95\", \"US715638BU55\", \"US715638DA73\", \"US715638DF60\", \"US715638DP43\", \"US715638DU38\", \"US715638EB48\", \"US715638DS81\", \"US715638BM30\", \"US715638DT64\", \"US715638EC21\", \"US715638DQ26\", \"US715638DW93\", \"US715638DR09\", \"US836205AT15\", \"US836205AW44\", \"US836205AU87\", \"US836205BA15\", \"US836205AY00\", \"US836205BC70\", \"US836205AS32\", \"US836205AV60\", \"US836205AX27\", \"US836205BB97\", \"US836205BE37\", \"US900123DB31\", \"US900123CJ75\", \"US900123CK49\", \"US900123CL22\", \"USM88269US88\", \"US900123DF45\", \"US900123CP36\", \"US900123CQ19\", \"US900123DH01\", \"US900123CT57\", \"US900123CY43\", \"US900123DJ66\", \"US900123DA57\", \"US900123DC14\", \"US900123DL13\", \"US900123DG28\", \"US900123DD96\", \"US900123AT75\", \"US900123DK30\", \"US900123DN78\", \"US900123AY60\", \"US900123BB58\", \"US900123BG46\", \"US900123BJ84\", \"US900123CB40\", \"US900123CG37\", \"US900123CM05\", \"USP3579EBK21\", \"USP3579EBV85\", \"USP3579ECB13\", \"USP3579ECP09\", \"USP3579ECF27\", \"USP3579ECR64\", \"USP3579ECH82\", \"USP3579ECN50\", \"USP3579ECU93\", \"USP3579ECJ49\", \"USP3579EAY34\", \"USP3579EBE60\", \"USP3579EBY25\", \"USP3579ECE51\", \"USP3579ECG00\", \"US71654QDH20\", \"US71654QBW15\", \"US71654QCB68\", \"US71654QDB59\", \"US71654QCG55\", \"US71654QCK67\", \"US71654QCP54\", \"US71654QDL32\", \"US71654QDC33\", \"US71654QDE98\", \"US71643VAB18\", \"US71654QDP46\", \"US706451BG56\", \"US71654QAZ54\", \"US71654QBR20\", \"US71654QCC42\", \"US71654QCL41\", \"US71654QDD16\", \"US71654QDF63\", \"US71656MAF68\", \"US71647NAS80\", \"US71647NAY58\", \"US71647NBH17\", \"US71647NBK46\", \"US71647NBL29\", \"US71645WAQ42\", \"US71645WAS08\", \"US71647NAK54\", \"US71647NBJ72\", \"US71647NAN93\",\n",
    "             \"XS2214237807\", \"XS2214239506\", \"XS2214238441\", \"XS2214239175\", \"US040114HX11\", \"US040114HS26\", \"US040114HT09\", \"US040114HU71\", \"US040114HV54\", \"US040114HW38\", \"XS1910826996\", \"XS1717011982\", \"XS2384698994\", \"XS2445169985\", \"XS1777972511\", \"XS1910827887\", \"XS2948511949\", \"XS1566179039\", \"XS2384701020\", \"XS2948512913\", \"XS1777972941\", \"XS1717013095\", \"XS1910828182\", \"XS2384704800\", \"XS1843435840\", \"XS1781710543\", \"XS2764839945\", \"XS1843435766\", \"XS2354781614\", \"XS1781710626\", \"XS1318576086\", \"XS1819680288\", \"XS2083302419\", \"XS2446175577\", \"XS1819680528\", \"XS2083302500\", \"XS1790104530\", \"XS1619155564\", \"XS2333676133\", \"XS1790134362\", \"XS2297220423\", \"XS1903488572\", \"XS1558078736\", \"XS2391394348\", \"XS1775618439\", \"XS1504948776\", \"XS1953057061\", \"XS1903489463\", \"XS2297226545\", \"XS2079842642\", \"XS2176897754\", \"XS2391395154\", \"XS1558078496\", \"XS1775617464\", \"XS1953057491\", \"XS2176899701\", \"XS2391398174\", \"USP01012BX31\", \"USP01012CF16\", \"XS0146173371\", \"USP01012AN67\", \"USP01012AR71\", \"USP01012CA29\", \"USP01012CC84\", \"USP01012CH71\", \n",
    "             \"USP7808BAA54\", \"USP7808BAB38\", \"XS0505478684\", \"XS2079846635\", \"XS2297221405\", \n",
    "             \"USG2583XAB76\", \"USL21779AL44\", \"USL21779AJ97\", \"USL21779AK60\", \n",
    "             \"XS2322319398\", \"XS1729875598\", \"XS2419405274\", \"XS2322319638\", \"XS2322321964\",\n",
    "             \"USN15516AB83\", \"USN15516AD40\", \"USN15516AH53\",\"USN15516AG70\",\"USN15516AJ10\",\"USU1065PAA94\",\n",
    "             \"USN15516AE23\"\n",
    "            ]\n",
    "isin_list += ['XS2965710598','US105756CL22','US105756CM05','US168863EE43','US195325ER27','US195325EQ44','US195325EP60','US195325ES00','US25714PFB94','US25714PFC77','XS2990500766','XS2989586941','XS3010561762','US91087BBB53','US91087BBF67','US91087BBE92','US91087BBC37','US91087BBD10','US715638FD94','US715638FC12','US836205BF02','XS2917537875','US900123DQ00']\n",
    "isin_list += [\"US60367QAC78\", \"US16955EAC49\", \"US455780CB07\", \"US455780BM70\", \"US455780BY19\", \"US455780BJ42\", \"US455780BU96\", \"US455780BW52\", \"US455780BR67\", \"US455780AX45\", \"US455780AZ92\", \"US455780AT33\", \"US455780CV60\", \"US455780CY00\", \"US455780CQ75\", \"US455780CR58\", \"US455780CW44\", \"US455780DG84\", \"US455780CX27\", \"US455780DJ24\", \"US455780CN45\", \"US455780CS32\", \"US455780DX18\", \"US455780CT15\", \"US455780DK96\", \"US455780CE46\", \"US455780CU87\", \"US455780DN36\", \"US455780DU78\", \"US455780DR40\", \"US455780DZ65\", \"US455780DV51\", \"US455780DW35\", \"US455780CJ33\", \"US455780EA06\", \"US455780DS23\"]\n",
    "\n",
    "names_list = [\"BRAZIL 6 04/07/26\", \"BRAZIL 4 5/8 01/13/28\", \"BRAZIL 4 1/2 05/30/29\", \"BRAZIL 3 7/8 06/12/30\", \"BRAZIL 6 1/4 03/18/31\", \"BRAZIL 3 3/4 09/12/31\", \"BRAZIL 6 1/8 01/22/32\", \"BRAZIL 6 10/20/33\", \"BRAZIL 6 1/8 03/15/34\", \"BRAZIL 5 01/27/45\", \"BRAZIL 5 5/8 02/21/47\", \"BRAZIL 4 3/4 01/14/50\", \"BRAZIL 7 1/8 05/13/54\", \"CHILE 2 3/4 01/31/27\", \"CHILE 3.24 02/06/28\", \"CHILE 4.85 01/22/29\", \"CHILE 2.45 01/31/31\", \"CHILE 2.55 01/27/32\", \"CHILE 2.55 07/27/33\", \"CHILE 3 1/2 01/31/34\", \"CHILE 4.95 01/05/36\", \"CHILE 3.1 05/07/41\", \"CHILE 4.34 03/07/42\", \"CHILE 3.86 06/21/47\", \"CHILE 3 1/2 01/25/50\", \"CHILE 4 01/31/52\", \"CHILE 3 1/2 04/15/53\", \"CHILE 5.33 01/05/54\", \"CHILE 3.1 01/22/61\", \"CHILE 3 1/4 09/21/2071\", \"COLOM 4 1/2 01/28/26\", \"COLOM 3 7/8 04/25/27\", \"COLOM 4 1/2 03/15/29\", \"COLOM 3 01/30/30\", \"COLOM 3 1/8 04/15/31\", \"COLOM 3 1/4 04/22/32\", \"COLOM 8 04/20/33\", \"COLOM 7 1/2 02/02/34\", \"COLOM 8 11/14/35\", \"COLOM 7 3/8 09/18/37\", \"COLOM 6 1/8 01/18/41\", \"COLOM 4 1/8 02/22/42\", \"COLOM 5 5/8 02/26/44\", \"COLOM 5 06/15/45\", \"COLOM 5.2 05/15/49\", \"COLOM 4 1/8 05/15/51\", \"COLOM 8 3/4 11/14/53\", \"COLOM 3 7/8 02/15/61\", \"MEX 4 1/8 01/21/26\", \"MEX 4.15 03/28/27\", \"MEX 3 3/4 01/11/28\", \"MEX 5.4 02/09/28\", \"MEX 4 1/2 04/22/29\", \"MEX 5 05/07/29\", \"MEX 3 1/4 04/16/30\", \"MEX 2.659 05/24/31\", \"MEX 4 3/4 04/27/32\", \"MEX 4 7/8 05/19/33\", \"MEX 3 1/2 02/12/34\", \"MEX 6.35 02/09/35\", \"MEX 6 05/07/36\", \"MEX 6.05 01/11/40\", \"MEX 4.28 08/14/41\", \"MEX 4 3/4 03/08/44\", \"MEX 5.55 01/21/45\", \"MEX 4.6 01/23/46\", \"MEX 4.35 01/15/47\", \"MEX 4.6 02/10/48\", \"MEX 4 1/2 01/31/50\", \"MEX 5 04/27/51\", \"MEX 4.4 02/12/52\", \"MEX 6.338 05/04/53\", \"MEX 6.4 05/07/54\", \"MEX 3.771 05/24/61\", \"MEX 3 3/4 04/19/2071\", \"MEX 5 3/4 10/12/2110\", \"PANAMA 3 3/4 04/17/26\", \"PANAMA 3 7/8 03/17/28\", \"PANAMA 3.16 01/23/30\", \"PANAMA 7 1/2 03/01/31\", \"PANAMA 3.362 06/30/31\", \"PANAMA 2.252 09/29/32\", \"PANAMA 3.298 01/19/33\", \"PANAMA 6.4 02/14/35\", \"PANAMA 6.7 01/26/36\", \"PANAMA 6 7/8 01/31/36\", \"PANAMA 8 03/01/38\", \"PANAMA 4 1/2 05/15/47\", \"PANAMA 4 1/2 04/16/50\", \"PANAMA 4.3 04/29/53\", \"PANAMA 6.853 03/28/54\", \"PANAMA 4 1/2 04/01/56\", \"PANAMA 3.87 07/23/60\", \"PANAMA 4 1/2 01/19/63\", \"PERU 2.392 01/23/26\", \"PERU 4 1/8 08/25/27\", \"PERU 2.844 06/20/30\", \"PERU 2.783 01/23/31\", \"PERU 1.862 12/01/32\", \"PERU 3 01/15/34\", \"PERU 5 3/8 02/08/35\", \"PERU 3.3 03/11/41\", \"PERU 5 5/8 11/18/50\", \"PERU 3.55 03/10/51\", \"PERU 5 7/8 08/08/54\", \"PERU 2.78 12/01/60\", \"PERU 3.6 01/15/2072\", \"PERU 3.23 07/28/2121\", \"SOAF 4 7/8 04/14/26\", \"SOAF 4.85 09/27/27\", \"SOAF 4.3 10/12/28\", \"SOAF 4.85 09/30/29\", \"SOAF 5 7/8 06/22/30\", \"SOAF 5 7/8 04/20/32\", \"SOAF 5 3/8 07/24/44\", \"SOAF 5 10/12/46\", \"SOAF 5.65 09/27/47\", \"SOAF 5 3/4 09/30/49\", \"SOAF 7.3 04/20/52\", \"TURKEY 4 3/4 01/26/26\", \"TURKEY 4 1/4 04/14/26\", \"TURKEY 4 7/8 10/09/26\", \"TURKEY 6 03/25/27\", \"TURKEY 8.6 09/24/27\", \"TURKEY 9 7/8 01/15/28\", \"TURKEY 5 1/8 02/17/28\", \"TURKEY 6 1/8 10/24/28\", \"TURKEY 9 3/8 03/14/29\", \"TURKEY 7 5/8 04/26/29\", \"TURKEY 5 1/4 03/13/30\", \"TURKEY 9 1/8 07/13/30\", \"TURKEY 5.95 01/15/31\", \"TURKEY 5 7/8 06/26/31\", \"TURKEY 7 1/8 07/17/32\", \"TURKEY 9 3/8 01/19/33\", \"TURKEY 6 1/2 09/20/33\", \"TURKEY 8 02/14/34\", \"TURKEY 7 5/8 05/15/34\", \"TURKEY 6 1/2 01/03/35\", \"TURKEY 6 7/8 03/17/36\", \"TURKEY 7 1/4 03/05/38\", \"TURKEY 6 3/4 05/30/40\", \"TURKEY 6 01/14/41\", \"TURKEY 4 7/8 04/16/43\", \"TURKEY 6 5/8 02/17/45\", \"TURKEY 5 3/4 05/11/47\", \"DOMREP 6 7/8 01/29/26\", \"DOMREP 5.95 01/25/27\", \"DOMREP 6 07/19/28\", \"DOMREP 5 1/2 02/22/29\", \"DOMREP 4 1/2 01/30/30\", \"DOMREP 7.05 02/03/31\", \"DOMREP 4 7/8 09/23/32\", \"DOMREP 6 02/22/33\", \"DOMREP 6.6 06/01/36\", \"DOMREP 5.3 01/21/41\", \"DOMREP 7.45 04/30/44\", \"DOMREP 6.85 01/27/45\", \"DOMREP 6 1/2 02/15/48\", \"DOMREP 6.4 06/05/49\", \"DOMREP 5 7/8 01/30/60\", \"PEMEX 6 7/8 10/16/25\", \"PEMEX 4 1/2 01/23/26\", \"PEMEX 6 7/8 08/04/26\", \"PEMEX 6.49 01/23/27\", \"PEMEX 6 1/2 03/13/27\", \"PEMEX 5.35 02/12/28\", \"PEMEX 6 1/2 01/23/29\", \"PEMEX 8 3/4 06/02/29\", \"PEMEX 6.84 01/23/30\", \"PEMEX 5.95 01/28/31\", \"PEMEX 6.7 02/16/32\", \"PEMEX 10 02/07/33\", \"PEMEX 6 5/8 06/15/35\", \"PEMEX 6 1/2 06/02/41\", \"PEMEX 6 3/8 01/23/45\", \"PEMEX 6 3/4 09/21/47\", \"PEMEX 6.35 02/12/48\", \"PEMEX 7.69 01/23/50\", \"PEMEX 6.95 01/28/60\", \"PEMEX 6 5/8 PERP\", \"PETBRA 7 3/8 01/17/27\", \"PETBRA 5.999 01/27/28\", \"PETBRA 5.6 01/03/31\", \"PETBRA 6 1/2 07/03/33\", \"PETBRA 6 01/13/35\", \"PETBRA 6 7/8 01/20/40\", \"PETBRA 6 3/4 01/27/41\", \"PETBRA 7 1/4 03/17/44\", \"PETBRA 5 1/2 06/10/51\", \"PETBRA 6.85 06/05/2115\",\n",
    "             \"ECUA 6.9 07/31/30\", \"ECUA 0 07/31/30\", \"ECUA 5 1/2 07/31/35\", \"ECUA 5 07/31/40\", \"ARGENT 1 07/09/29\", \"ARGENT 0 3/4 07/09/30\", \"ARGENT 4 1/8 07/09/35\", \"ARGENT 5 01/09/38\", \"ARGENT 3 1/2 07/09/41\", \"ARGENT 4 1/8 07/09/46\", \"NGERIA 7 5/8 11/21/25\", \"NGERIA 6 1/2 11/28/27\", \"NGERIA 6 1/8 09/28/28\", \"NGERIA 8 3/8 03/24/29\", \"NGERIA 7.143 02/23/30\", \"NGERIA 8.747 01/21/31\", \"NGERIA 9 5/8 06/09/31\", \"NGERIA 7 7/8 02/16/32\", \"NGERIA 7 3/8 09/28/33\", \"NGERIA 10 3/8 12/09/34\", \"NGERIA 7.696 02/23/38\", \"NGERIA 7 5/8 11/28/47\", \"NGERIA 9.248 01/21/49\", \"NGERIA 8 1/4 09/28/51\", \"KENINT 7 05/22/27\", \"KENINT 7 1/4 02/28/28\", \"KENINT 9 3/4 02/16/31\", \"KENINT 8 05/22/32\", \"KENINT 6.3 01/23/34\", \"KENINT 8 1/4 02/28/48\", \"ANGOL 9 1/2 11/12/25\", \"ANGOL 8 1/4 05/09/28\", \"ANGOL 8 11/26/29\", \"ANGOL 8 3/4 04/14/32\", \"ANGOL 9 3/8 05/08/48\", \"ANGOL 9 1/8 11/26/49\", \"SENEGL 4 3/4 03/13/28\", \"SENEGL 6 1/4 05/23/33\", \"SENEGL 5 3/8 06/08/37\", \"SENEGL 6 3/4 03/13/48\", \"EGYPT 3 7/8 02/16/26\", \"EGYPT 7 1/8 11/10/26\", \"EGYPT 7 1/2 01/31/27\", \"EGYPT 5.8 09/30/27\", \"EGYPT 6.588 02/21/28\", \"EGYPT 7 11/10/28\", \"EGYPT 7.6003 03/01/29\", \"EGYPT 7 5/8 11/10/30\", \"EGYPT 5 7/8 02/16/31\", \"EGYPT 7.0529 01/15/32\", \"EGYPT 7 5/8 05/29/32\", \"EGYPT 7.3 09/30/33\", \"EGYPT 8 1/2 01/31/47\", \"EGYPT 7.903 02/21/48\", \"EGYPT 8.7002 03/01/49\", \"EGYPT 8 7/8 05/29/50\", \"EGYPT 8 3/4 09/30/51\", \"ELSALV 8 5/8 02/28/29\", \"ELSALV 9 1/4 04/17/30\", \"ELSALV 8 1/4 04/10/32\", \"ELSALV 7.65 06/15/35\", \"ELSALV 7 5/8 02/01/41\", \"ELSALV 7.1246 01/20/50\", \"ELSALV 9 1/2 07/15/52\", \"ELSALV 9.65 11/21/54\", \n",
    "             \"PETRPE 4 3/4 06/19/32\", \"PETRPE 5 5/8 06/19/47\", \"EGYPT 6 7/8 04/30/40\", \"EGYPT 8.15 11/20/59\", \"EGYPT 7 1/2 02/16/61\", \n",
    "             \"CSNABZ 6 3/4 01/28/28\", \"CSNABZ 8 7/8 12/05/30\", \"CSNABZ 4 5/8 06/10/31\", \"CSNABZ 5 7/8 04/08/32\",\n",
    "             \"PKSTAN 6 04/08/26\", \"PKSTAN 6 7/8 12/05/27\", \"PKSTAN 7.95 01/31/29\", \"PKSTAN 7 3/8 04/08/31\", \"PKSTAN 8 7/8 04/08/51\",\n",
    "             \"BRASKM 4.5 01/10/28\", \"BRASKM 4.5 01/31/30\",\"BRASKM 8.5 01/12/31\",\"BRASKM 7.25 02/13/33\",\"BRASKM 8 10/15/34\",\"BRASKM 7.125 07/22/41\", \"BRASKM 5.875 01/31/50\",\n",
    "             ]\n",
    "names_list += ['ANGOL 10.95 12/27/30', 'BRAZIL 6 5/8 03/15/35', 'BRAZIL 5 1/2 11/06/30', 'CHILE 5.65 01/13/37', 'COLOM 7 3/8 04/25/30', 'COLOM 8 3/8 11/07/54', 'COLOM 7 3/4 11/07/36', 'COLOM 8 1/2 04/25/35', 'DOMREP 6.95 03/15/37', 'DOMREP 7.15 02/24/55', 'EGYPT 9.45 02/04/33', 'EGYPT 8 5/8 02/04/30', 'KENINT 9 1/2 03/05/36', 'MEX 6 05/13/30', 'MEX 6 5/8 01/29/38', 'MEX 5.85 07/02/32', 'MEX 6 7/8 05/13/37', 'MEX 7 3/8 05/13/55', 'PERU 6.2 06/30/55', 'PERU 5 1/2 03/30/36', 'SOAF 7.1 11/19/36', 'SOAF 7.95 11/19/54', 'TURKEY 7 1/4 05/29/32']\n",
    "names_list += [\"CHINA 1 3/4 10/26/31\", \"CHINA 1.2 10/21/30\", \"INDON 4 3/4 07/18/47\", \"INDON 4 5/8 04/15/43\", \"INDON 5 1/4 01/08/47\", \"INDON 5 1/4 01/17/42\", \"INDON 5 1/8 01/15/45\", \"INDON 5.95 01/08/46\", \"INDON 6 3/4 01/15/44\", \"INDON 6 5/8 02/17/37\", \"INDON 7 3/4 01/17/38\", \"INDON 8 1/2 10/12/35\", \"INDON 1.85 03/12/31\", \"INDON 2.15 07/28/31\", \"INDON 2.85 02/14/30\", \"INDON 3 1/2 02/14/50\", \"INDON 3.05 03/12/51\", \"INDON 3.2 09/23/61\", \"INDON 3.35 03/12/2071\", \"INDON 3.55 03/31/32\", \"INDON 3.7 10/30/49\", \"INDON 3.85 10/15/30\", \"INDON 4 3/4 09/10/34\", \"INDON 4.2 10/15/50\", \"INDON 4.3 03/31/52\", \"INDON 4.35 01/11/48\", \"INDON 4.45 04/15/70\", \"INDON 4.65 09/20/32\", \"INDON 4.7 02/10/34\", \"INDON 4.85 01/11/33\", \"INDON 5 1/4 01/15/30\", \"INDON 5.1 02/10/54\", \"INDON 5.15 09/10/54\", \"INDON 5.35 02/11/49\", \"INDON 5.6 01/15/35\", \"INDON 5.65 01/11/53\"]\n",
    "\n",
    "#Making Manual Adj. for Perp Bond of PEMEX\n",
    "names_list[names_list.index(\"PEMEX 6 5/8 PERP\")] = \"PEMEX 6 5/8 01/01/9999\"\n",
    "##################  Change here only\n",
    "\n",
    "names_list = [item.split(' ',1)[0] + ' ' + item.rsplit(' ',1)[0].split(' ',1)[1] + '% due ' + item.rsplit('/',1)[-1] for item in names_list]\n",
    "\n",
    "fields = [          \n",
    "          [\"DB(SAGE,INSTRUMENT,id_isin,\", \",StatCdsPESpreadAsk)\"],\n",
    "          [\"DB(SAGE,INSTRUMENT,id_isin,\", \",StatCdsPESpreadBid)\"],\n",
    "          [\"DB(SAGE,INSTRUMENT,id_isin,\", \",StatCdsBasis)\"],\n",
    "         ]\n",
    "\n",
    "field_names = ['PECS Ask', 'PECS Bid','Basis',]\n",
    "\n",
    "dq_list = []\n",
    "full_names = []\n",
    "\n",
    "for i in range(len(isin_list)):\n",
    "    for j in range(len(fields)):\n",
    "        dq_list = dq_list + [fields[j][0] + isin_list[i] + fields[j][1]]\n",
    "        full_names = full_names + [names_list[i] + ' ' + field_names[j]]\n",
    "\n",
    "labels = dict(zip(full_names, dq_list))\n",
    "\n",
    "######################################################### Hash this for non-live\n",
    "try:\n",
    "    if global_update_live:\n",
    "        cl = 'jbAIMF2Tkp0JO3sc'\n",
    "        # cl = '0'\n",
    "    dq = DataQuery(\n",
    "    client_id=cl,\n",
    "    client_secret='d7qfzgt55pddjs352sgxosFyI4t2eja07k7opbi6wg9oqjc1OjkdAksn1btmnugeMjchcx2vwTsJupw',\n",
    "    )\n",
    "    job = dq.create_job(expressions = list(labels.values()))\n",
    "    dq.start_date = 'TODAY-5Y'\n",
    "    job.execute(alert_long_requests='ignore')\n",
    "    df = job.to_pivot_table()\n",
    "    df = df.T\n",
    "    df.index.name = 'Date'\n",
    "    df.index = pd.to_datetime(df.index, format='%Y%m%d').date\n",
    "    df.columns.name = None\n",
    "    \n",
    "    df1 = pd.DataFrame()\n",
    "    for key in labels:\n",
    "        df1[key] = df[labels[key]]\n",
    "    \n",
    "    df1 = df1[list(labels.keys())].copy()\n",
    "    clear_output(wait=False)\n",
    "    df1.dropna(axis=1, how='all', inplace=True)\n",
    "    \n",
    "    df1.columns = df1.columns.str.replace(\"DQ PECS\", \"DQ PECS Rich/Cheap\")\n",
    "    df1.columns = df1.columns.str.replace(\"DQ Z_SPREAD\", \"DQ Z_SPREAD Rich/Cheap\")\n",
    "    df_back = df1.copy()\n",
    "    df_back.to_excel(\"DQ_Data_v75.xlsx\")\n",
    "    \n",
    "    # else:\n",
    "    #     df_back = pd.concat([df_back[~df_back.index.isin(df.index)], df])\n",
    "    #     df_back.to_excel(\"DQ_Data_v75.xlsx\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Using old JPM data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec475d55-89fc-490f-9f7e-11205368f40f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    if not global_update_live:\n",
    "        df_original = pd.read_parquet(\"Markit CDS.parquet/\")\n",
    "        df_original2 = pd.read_parquet(\"Markit Upfronts.parquet/\")\n",
    "    else:\n",
    "        df_original = pd.read_parquet(\"Markit CDS.parquet\")\n",
    "        df_original2 = pd.read_parquet(\"Markit Upfronts.parquet\")\n",
    "\n",
    "    # df_original = pd.read_parquet(\"Markit CDS.parquet\")\n",
    "    # df_original2 = pd.read_parquet(\"Markit Upfronts.parquet\")\n",
    "    \n",
    "    to_date = datetime.today().date()\n",
    "    from_date = df_original[\"close_date\"].iloc[-1].date()\n",
    "    from_date2 = df_original2[\"close_date\"].iloc[-1].date()\n",
    "    \n",
    "    from_date = min(from_date, from_date2)    \n",
    "    from_date_str = from_date.strftime('%m/%d/%Y')\n",
    "    to_date_str = to_date.strftime('%m/%d/%Y')\n",
    "    \n",
    "    conn_str = (\n",
    "        f'DRIVER={{SQL Server}};'\n",
    "        f'SERVER=BC-ODS-P1;'\n",
    "        f'DATABASE=MarkitDB;'\n",
    "        f'ApplicationIntent=ReadOnly;'\n",
    "        f'Trusted_Connection=Yes;'\n",
    "        f'Authentication=ActiveDirectoryIntegrated;'\n",
    "    )\n",
    "    \n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    \n",
    "    query1 = f\"\"\"\n",
    "        DECLARE @FromDate DATE = '{from_date_str}';\n",
    "        DECLARE @ToDate DATE = '{to_date_str}';\n",
    "        \n",
    "        SELECT sc.close_date, r.ticker, c.red, c.tier, c.docclause, c.ccy, sc.tenor, sc.spread\n",
    "        FROM dbo.RedEntities r\n",
    "        INNER JOIN dbo.MarkitCurves c ON r.red = c.red\n",
    "        INNER JOIN dbo.MarkitSpreadCurve sc ON c.curve_id = sc.curve_id\n",
    "        WHERE sc.close_date >= @FromDate AND sc.close_date <= @ToDate;\n",
    "    \"\"\"\n",
    "\n",
    "    query2 = f\"\"\" \n",
    "        DECLARE @FromDate DATE = '{from_date_str}';\n",
    "        DECLARE @ToDate DATE = '{to_date_str}';\n",
    "        \n",
    "        Select uf.close_date, r.ticker, c.red, c.tier, c.docclause, c.ccy, uf.coupon, ufc.tenor, ufc.fee, ufc.spread, ufc.calculated_fee, ufc.calculated_spread\n",
    "        From dbo.RedEntities r\n",
    "        Inner Join dbo.MarkitCurves c On r.red = c.red\n",
    "        Inner Join dbo.MarkitUpfronts uf On c.curve_id = uf.curve_id\n",
    "        Inner Join dbo.MarkitUpfrontFees ufc On uf.curve_id = ufc.curve_id And uf.coupon = ufc.coupon And uf.close_date = ufc.close_date\n",
    "        Where uf.close_date >= @FromDate And uf.close_date <= @ToDate\n",
    "     \"\"\"\n",
    "\n",
    "    df_new = pd.read_sql(query1, conn)\n",
    "    df_new2 = pd.read_sql(query2, conn)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    df_old = df_original[df_original[\"close_date\"]<pd.to_datetime(from_date)]\n",
    "    df_old2 = df_original2[df_original2[\"close_date\"]<pd.to_datetime(from_date)]\n",
    "\n",
    "    df1 = pd.concat([df_old, df_new])\n",
    "    df1 = df1.drop_duplicates()\n",
    "    df1.to_parquet(\"Markit CDS.parquet\")\n",
    "\n",
    "    df2 = pd.concat([df_old2, df_new2])\n",
    "    df2 = df2.drop_duplicates()\n",
    "    df2.to_parquet(\"Markit Upfronts.parquet\")\n",
    "except:\n",
    "    df1 = pd.read_parquet(\"Markit CDS.parquet\")\n",
    "    df2 = pd.read_parquet(\"Markit Upfronts.parquet\")\n",
    "    print(\"Using Old Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d4ae33c-73a8-47b2-9eb1-cdcfae75c321",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "markit_uf = df2.drop(\"calculated_spread\",axis=1).copy()\n",
    "markit_par = df1.copy()\n",
    "\n",
    "markit_uf[\"fee\"] = markit_uf[\"fee\"].fillna(markit_uf[\"calculated_fee\"])\n",
    "markit_uf[\"spread\"] = markit_uf[\"fee\"]\n",
    "markit_uf = markit_uf.drop([\"calculated_fee\",\"fee\"],axis=1)\n",
    "\n",
    "markit_uf100 = markit_uf[markit_uf[\"coupon\"]==100].drop(\"coupon\", axis=1).reset_index(drop=True).copy()\n",
    "markit_uf500 = markit_uf[markit_uf[\"coupon\"]==500].drop(\"coupon\", axis=1).reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c88addd8-9cd9-4db2-8b2a-d790d057d6f3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "f_dict = {}\n",
    "dt_list = []\n",
    "last_update = None\n",
    "\n",
    "def three_curves(df1, update_live, data_type):\n",
    "    global f_dict\n",
    "    global dt_list\n",
    "    global last_update\n",
    "    \n",
    "    # active_tickers = list(set(df1[df1[\"close_date\"]==df1[\"close_date\"].iloc[-1]][\"ticker\"]))\n",
    "    # df1 = df1[df1[\"ticker\"].isin(active_tickers)].reset_index(drop=True).copy()\n",
    "    \n",
    "    markit_cds = list(set(df1[\"red\"]))\n",
    "    markit_df1 = df1.copy()\n",
    "    \n",
    "    res_codes = { \"Full Restructuring\": \"CR14\", \"Modified Restructuring\": \"MR14\",\n",
    "              \"Modified-Modified Restructurin\": \"MM14\", \"No Restructuring\": \"XR14\"}\n",
    "    \n",
    "    excel_df = None\n",
    "    all_dq = None\n",
    "    all_temp_cds = None\n",
    "    \n",
    "    for rating_col in[\"IG\",\"HY\",\"EUR_IG\",\"EUR_HY\",\"SNRFIN\",\"SUBFIN\",\"Extras\"]:\n",
    "        dq = pd.read_excel(\"New CDX Members.xlsx\", sheet_name=rating_col)\n",
    "        # dq = pd.read_excel(\"CDX Members.xlsx\", sheet_name=rating_col)\n",
    "        dq[\"Restructuring\"] = dq[\"Restructuring\"].apply(lambda x: res_codes[x])\n",
    "        dq = dq[dq[\"Actual RED Code\"].isin(markit_cds)].reset_index(drop=True).copy()\n",
    "        dq.rename(columns={\"Actual RED Code\": \"red\"}, inplace=True)\n",
    "        \n",
    "        if not \"Family\" in dq.columns:\n",
    "            dq[\"Family\"] = [rating_col]*len(dq)\n",
    "            \n",
    "        if not \"tier\" in dq.columns:\n",
    "            dq[\"tier\"] = \"SNRFOR\" if rating_col != \"SUBFIN\" else \"SUBLT2\"\n",
    "        \n",
    "        dq[\"ccy\"] = dq[\"Family\"].apply(lambda x: \"USD\" if x in [\"IG\",\"HY\"] else \"EUR\")\n",
    "        dq = dq.drop([\"5Y CDS Ticker\",\"ISIN\",\"RED Code\",\"Company Name\",\"Corp Ticker\"],axis=1)\n",
    "        \n",
    "        all_dq = pd.concat([all_dq, dq]).drop_duplicates(keep=\"first\").reset_index(drop=True).copy()\n",
    "    \n",
    "    unique_all_dq = all_dq.drop(\"Family\",axis=1).drop_duplicates().reset_index(drop=True).copy()\n",
    "    unique_all_dq.columns = unique_all_dq.columns.str.replace(\"Restructuring\",\"docclause\")\n",
    "    \n",
    "    cds_df = pd.merge(left=markit_df1, right = unique_all_dq, on=[\"red\",\"docclause\",\"tier\",\"ccy\"], how=\"inner\")\n",
    "    cds_df[\"close_date\"] = pd.to_datetime(cds_df[\"close_date\"])\n",
    "    cds_df = cds_df[cds_df[\"tenor\"]!=\"Spot\"]\n",
    "    cds_df[\"tenor\"] = cds_df[\"tenor\"].apply(lambda x: eval(x.replace(\"y\",\"*1\").replace(\"m\",\"*(1/12)\")))\n",
    "    \n",
    "    cds_df[\"ticker_red_tier_ccy_docclause\"] = (cds_df[\"ticker\"].astype(str) + \"_\" + cds_df[\"red\"].astype(str) +\\\n",
    "         \"_\" + cds_df[\"tier\"].astype(str) + \"_\" + cds_df[\"ccy\"].astype(str) + \"_\" + cds_df[\"docclause\"].astype(str))\n",
    "    cds_df = cds_df.drop([\"ticker\",\"red\",\"tier\",\"ccy\",\"docclause\"],axis=1)\n",
    "    \n",
    "    ########################### Only for HY quoted spread df\n",
    "    if \"fee\" in cds_df.columns:\n",
    "        cds_df = cds_df[cds_df[\"coupon\"]==100].drop([\"coupon\"], axis=1).copy()\n",
    "        cds_df = cds_df[~pd.isna(cds_df[\"fee\"]) | ~pd.isna(cds_df[\"calculated_fee\"])].reset_index(drop=True).copy()\n",
    "    \n",
    "    ########################### Creating map for family\n",
    "    f = all_dq.drop_duplicates().reset_index(drop=True).copy()\n",
    "    f1 = f[\"Issuer Equity\"].astype(str) + \"_\" + f[\"red\"].astype(str) + \"_\" +\\\n",
    "    f[\"tier\"].astype(str) + \"_\" + f[\"ccy\"].astype(str)  + \"_\" + f[\"Restructuring\"].astype(str)\n",
    "    f2 = f[\"Family\"]\n",
    "    f_dict = dict(zip(f1,f2))\n",
    "    \n",
    "    \n",
    "    ############################################################################################################## NEW BLOCK\n",
    "    \n",
    "    issuers = list(sorted(set(cds_df[\"ticker_red_tier_ccy_docclause\"])))\n",
    "    last_dt = max(cds_df[\"close_date\"])\n",
    "    \n",
    "    all_curves = None\n",
    "    \n",
    "    try:\n",
    "        if not update_live:\n",
    "            all_curves = pd.read_excel(\"All CDS Curves Par.xlsx/\") ############## made to fail\n",
    "        for issuer in issuers:\n",
    "            df = cds_df[cds_df[\"ticker_red_tier_ccy_docclause\"]==issuer]\n",
    "            df = pd.pivot_table(df, values=\"spread\", index=\"close_date\", columns =\"tenor\")\n",
    "            \n",
    "            if not last_dt in df.index:\n",
    "                df.loc[last_dt] = [np.nan] * len(df.columns)\n",
    "            df = df.sort_index().ffill().copy()\n",
    "            df[f\"{issuer}_curve\"] = [np.nan] * len(df)\n",
    "        \n",
    "            for idx in df.index:\n",
    "                curve = df.loc[[idx],:].dropna(axis=1)\n",
    "                curve = curve.iloc[:,:-1].copy()\n",
    "                x = list((curve.columns))\n",
    "                x2 = [item**2 for item in x]\n",
    "                X = np.column_stack([x, x2])\n",
    "                Y = list(curve.iloc[0])\n",
    "        \n",
    "                if len(X) > 2:\n",
    "                    model = sm.OLS(Y, sm.add_constant(X)).fit()\n",
    "                    df.loc[idx,f\"{issuer}_curve\"] = str([model.params[0], model.params[1], model.params[2]])\n",
    "                    \n",
    "                    # x_pred = list(np.linspace(min(x), max(x),100))\n",
    "                    # x_pred2 = [item**2 for item in x_pred]\n",
    "                    # X_pred = np.column_stack([x_pred, x_pred2])\n",
    "                    # y_pred = model.predict(sm.add_constant(X_pred))\n",
    "                    # plt.plot(x, Y)\n",
    "                    # plt.plot(x_pred, y_pred)\n",
    "                    # title = f\"{issuer} on {str(idx.date())}\"\n",
    "                    # plt.title(title)\n",
    "                    # # plt.savefig(f\"Curve Plots v2/{title}.png\")\n",
    "                    # plt.show()\n",
    "                    # plt.close()\n",
    "                    \n",
    "                else:\n",
    "                    df.loc[idx,f\"{issuer}_curve\"] = str([np.nan, np.nan, np.nan])\n",
    "        \n",
    "            all_curves = pd.concat([all_curves,df.iloc[:,[-1]]],axis=1)\n",
    "        all_curves.to_excel(f\"All CDS Curves_{data_type}.xlsx\")\n",
    "    except:\n",
    "        all_curves = pd.read_excel(f\"All CDS Curves_{data_type}.xlsx\",index_col=0, parse_dates=True)\n",
    "    \n",
    "    all_curves1 = all_curves.copy()\n",
    "    all_curves = all_curves.T.copy()\n",
    "    all_curves.index.name = \"ticker_red_tier_ccy_docclause\"\n",
    "    all_curves.columns = [f'CDS_{item.date()}' for item in all_curves.columns]\n",
    "    all_curves = all_curves.reset_index(drop=False).copy()\n",
    "    all_temp_cds = all_curves.copy()\n",
    "    all_temp_cds[\"Temp\"] = (all_temp_cds[\"ticker_red_tier_ccy_docclause\"].astype(str).\\\n",
    "        str.split(\"_\", n=1).str[1].str.replace(\"_curve\", \"\", regex=False))\n",
    "    ############################################################################################################## NEW BLOCK\n",
    "    \n",
    "    unique_all_dq[\"Issuer Equity_red_tier_ccy_docclause\"] = (unique_all_dq[\"Issuer Equity\"].astype(str) + \"_\" + unique_all_dq[\"red\"].astype(str) +\\\n",
    "         \"_\" + unique_all_dq[\"tier\"].astype(str) + \"_\" + unique_all_dq[\"ccy\"].astype(str) + \"_\" + unique_all_dq[\"docclause\"].astype(str))\n",
    "    unique_all_dq = unique_all_dq.drop([\"Issuer Equity\",\"red\",\"tier\",\"ccy\",\"docclause\"],axis=1)\n",
    "    unique_all_dq[\"Temp\"] = unique_all_dq[\"Issuer Equity_red_tier_ccy_docclause\"].astype(str).str.split(\"_\", n=1).str[1]\n",
    "    \n",
    "    df2 = pd.merge(left=unique_all_dq, right=all_temp_cds, on=\"Temp\", how=\"inner\").drop([\"Temp\",\"ticker_red_tier_ccy_docclause\"], axis=1)\n",
    "    \n",
    "    ############################################################################################################## NEW BLOCK\n",
    "    \n",
    "    markit_to_bbg_tier_map = {\"SNRFOR\": \"Sr Unsecured\", \"SUBLT2\": \"Subordinated\"}\n",
    "    \n",
    "    l1 = [item.split(\"_\")[0] for item in df2[\"Issuer Equity_red_tier_ccy_docclause\"]]\n",
    "    l2 = [markit_to_bbg_tier_map[item.split(\"_\")[2]] for item in df2[\"Issuer Equity_red_tier_ccy_docclause\"]]\n",
    "    l3 = [item.split(\"_\")[3] for item in df2[\"Issuer Equity_red_tier_ccy_docclause\"]]\n",
    "    l4 = [item.split(\" \")[0] for item in df2[\"Bond Name\"]]\n",
    "    bbg_bonds_dict = {}\n",
    "    \n",
    "    for i in range(len(l1)):\n",
    "        bbg_bonds_dict[f\"{l1[i]} Equity_{l2[i]}_{l3[i]}\"] = l4[i]\n",
    "        \n",
    "    ############################################################################################################## NEW BLOCK\n",
    "    # ##########################################################################This Data was copied to All Bonds sheet\n",
    "    # bql_list = []\n",
    "    \n",
    "    # fl = [f\"\"\"=BQL(\"filter(bonds(['\"\"\",\n",
    "    #       f\"\"\"']), payment_rank=='\"\"\",\n",
    "    #       f\"\"\"' AND crncy=='\"\"\",\n",
    "    #       f\"\"\"')\", \"id_isin, id_cusip, name, maturity, amt_outstanding\")\"\"\"]\n",
    "    \n",
    "    # for item, key in bbg_bonds_dict.items():\n",
    "    #     bql_list += [fl[0] + item.split(\"_\")[0] + fl[1] + item.split(\"_\")[1] + fl[2] + item.split(\"_\")[2] + fl[3]]\n",
    "    \n",
    "        \n",
    "    # bql_list = [item.replace(\"\\\\\", \"\") for item in bql_list]\n",
    "    \n",
    "    # workbook = openpyxl.load_workbook(r\"J:\\\\HY Basis Data.xlsx\")\n",
    "    # sheet = workbook.active\n",
    "    \n",
    "    # for row in sheet.iter_rows():\n",
    "    #     for cell in row:\n",
    "    #         cell.value = None\n",
    "    \n",
    "    # start_col = 1\n",
    "    # for item in bql_list:\n",
    "    #     cell = sheet.cell(row=2, column=start_col)\n",
    "    #     cell.value = item\n",
    "    #     start_col += 6\n",
    "    # workbook.save(r\"J:\\\\HY Basis Data.xlsx\")\n",
    "    \n",
    "    # file_path = r\"J:\\\\HY Basis Data.xlsx\"\n",
    "    # window_title = \"HY Basis Data - Excel\"\n",
    "    \n",
    "    # subprocess.Popen(['start', 'excel', file_path], shell=True)\n",
    "    # time.sleep(5)\n",
    "    \n",
    "    # excel_windows = [window for window in gw.getWindowsWithTitle('Excel')]\n",
    "    \n",
    "    # for window in excel_windows:\n",
    "    #     if window_title in window.title:\n",
    "    #         # time.sleep(0.5)\n",
    "    #         window.activate()\n",
    "    #         break\n",
    "    \n",
    "    # time.sleep(45)\n",
    "    # pyautogui.hotkey('ctrl', 's')\n",
    "    # time.sleep(1)\n",
    "    # # pyautogui.hotkey('alt', 'f4')\n",
    "    \n",
    "    # time.sleep(1.5)\n",
    "    \n",
    "    ############################################################################################################## NEW BLOCK\n",
    "    \n",
    "    bonds_map = []\n",
    "    markit_to_bbg_tier_map_reverse = dict(zip(list(markit_to_bbg_tier_map.values()), list(markit_to_bbg_tier_map.keys())))\n",
    "    \n",
    "    for i in range(len(l1)):\n",
    "        bonds_map += [f\"{l1[i]}_{markit_to_bbg_tier_map_reverse[l2[i]]}_{l3[i]}\"]\n",
    "        \n",
    "    ############################################################################################################## NEW BLOCK\n",
    "    # df = pd.read_excel(\"All Bonds.xlsx\", sheet_name=\"All Bonds\")\n",
    "    df = pd.read_excel(\"All Bonds.xlsx\", sheet_name=\"New All Bonds\")\n",
    "    l5 = [item.split(\"_\")[0].replace(\" Equity\",\"\") + \"_\" + markit_to_bbg_tier_map_reverse[item.split(\"_\")[1]] +\\\n",
    "          \"_\" + item.split(\"_\")[2] for item in list(bbg_bonds_dict.keys())]\n",
    "    l6 = list(bbg_bonds_dict.values())\n",
    "    \n",
    "    all_df = None\n",
    "    \n",
    "    for i in range(len(df.columns))[::6]:\n",
    "        x = df.iloc[:,i:i+6].dropna().copy()\n",
    "        # try:\n",
    "        if len(x) > 0:\n",
    "            x.columns = ['ID','ISIN', \"CUSIP\", 'Name', 'Maturity','Amt']\n",
    "            x[\"Issuer Equity_tier_ccy\"] = [l5[int(i/6)]] * len(x)\n",
    "            x[\"Bond Name\"] = [l6[int(i/6)]] * len(x)\n",
    "            x[\"Check Col\"] = x.apply(lambda row: row[\"Name\"].split(\" \")[0]==row[\"Bond Name\"],axis=1)\n",
    "            x = x[x[\"Check Col\"]].drop([\"Check Col\",\"Bond Name\"],axis=1)\n",
    "            all_df = pd.concat([all_df, x])\n",
    "        # except:\n",
    "        #     hello = 1\n",
    "    \n",
    "    all_df['Time'] = round(((pd.to_datetime(all_df['Maturity'])-datetime.now()).dt.days/365),2)\n",
    "    all_df = all_df[all_df[\"Time\"]>=0]\n",
    "    all_df = all_df[(all_df['Time']>=4) & (all_df['Time']<=10)]\n",
    "    all_df = all_df[all_df['Amt']>=300*10**6]\n",
    "    all_df = all_df.reset_index(drop=True)\n",
    "    excel_df = pd.concat([excel_df, all_df])\n",
    "    all_df = excel_df.copy()\n",
    "    \n",
    "    all_df = all_df.drop_duplicates(keep=\"first\").reset_index(drop=True).copy()\n",
    "    \n",
    "    ########################################################################################### 144A and REGS\n",
    "    \n",
    "    blist = [f'/isin/{item}@BGN' for item in list(all_df[\"ISIN\"])]\n",
    "    if update_live and data_type==\"Par\":\n",
    "        blist = blp.bdp(tickers=blist, flds=[\"144A_FLAG\",\"IS_REG_S\"])\n",
    "        blist.to_parquet(\"BBG 144A.parquet\")\n",
    "    blist = pd.read_parquet(\"BBG 144A.parquet\")\n",
    "    blist.index = [item.rsplit(\"/\",1)[1].split(\"@\")[0] for item in blist.index]\n",
    "    \n",
    "    blist.columns = [\"144A\",\"REGS\"]\n",
    "    blist.index.name = \"ISIN\"\n",
    "    blist = blist.reset_index()\n",
    "    blist[\"REGS_144A\"] = blist.apply(lambda row: f'{row[\"REGS\"]}_{row[\"144A\"]}',axis=1)\n",
    "    order = [\"N_N\", \"Y_N\", \"Y_Y\", \"N_Y\"]\n",
    "    \n",
    "    all_df = pd.merge(left=all_df, right=blist, on=\"ISIN\", how=\"outer\")\n",
    "    all_df = all_df[[item for item in all_df.columns if not item in [\"144A\",\"REGS\"]]]\n",
    "    \n",
    "    all_df[\"REGS_144A\"] = pd.Categorical(all_df[\"REGS_144A\"], categories=order, ordered=True)\n",
    "    all_df = all_df.sort_values(by=\"REGS_144A\")\n",
    "    all_df = all_df[~all_df[\"Name\"].duplicated(keep='first')].drop([\"REGS_144A\",\"Time\"],axis=1).reset_index(drop=True).copy()\n",
    "    \n",
    "    ############################################################################################################## NEW BLOCK\n",
    "    \n",
    "    t = [f\"/isin/{item}@BGN\" for item in list(all_df[\"ISIN\"])]\n",
    "    if update_live and data_type==\"Par\":\n",
    "        bbg = blp.bdh(tickers=t, flds=\"BLOOMBERG_MID_G_SPREAD\", start_date=datetime.now()-timedelta(days=365*5))\n",
    "        bbg.to_parquet(\"BBG G_Sprds.parquet\")\n",
    "    bbg = pd.read_parquet(\"BBG G_Sprds.parquet\")\n",
    "    \n",
    "    bbg1 = bbg.copy()\n",
    "    new = []\n",
    "    for item in bbg1.columns:\n",
    "        new += [\"BBG_\" + item[0].replace(\"/isin/\",\"\").replace(\"@BGN\",\"\")]\n",
    "    bbg1.columns = new\n",
    "    bbg1.index = pd.to_datetime(bbg1.index)\n",
    "    \n",
    "    ############################################################ choose bbg or dq sprds\n",
    "    \n",
    "    bbg1.columns = [item.split(\"_\")[1] for item in bbg1.columns]\n",
    "    bbg1.index = [f\"Sprd_{str(item.date())}\" for item in bbg1.index]\n",
    "    bbg1 = bbg1.T.copy()\n",
    "    bbg1.index.name = \"ISIN\"\n",
    "    bbg1 = bbg1.reset_index(drop=False).copy()\n",
    "    \n",
    "    ############################################################################################################## NEW BLOCK\n",
    "    \n",
    "    df2a = df2.drop([\"Primary ISIN\",\"Bond Name\"],axis=1).copy()\n",
    "    df2a[\"Issuer Equity_tier_ccy\"] = [item.split(\"_\")[0] + \"_\" + item.split(\"_\")[2] +\\\n",
    "                   \"_\" + item.split(\"_\")[3] for item in df2a[\"Issuer Equity_red_tier_ccy_docclause\"]]\n",
    "    # df2a = df2a.replace(np.nan,\"[np.nan, np.nan, np.nan]\")\n",
    "    df3 = pd.merge(left=all_df, right=df2a, on=\"Issuer Equity_tier_ccy\",\\\n",
    "                   how=\"inner\").drop([\"ID\",\"Amt\",\"Issuer Equity_tier_ccy\"],axis=1).copy()\n",
    "    \n",
    "    for dt in pd.to_datetime(bbg.index):\n",
    "        df3[f'Mat_Time_{dt.date()}'] = [((pd.to_datetime(item) - dt).days/365) for item in df3[\"Maturity\"]]\n",
    "    \n",
    "    df4A = df3.copy()\n",
    "    dt_list = [item.replace(\"CDS_\",\"\") for item in df4A.columns if item.startswith(\"CDS_\")]\n",
    "    \n",
    "    def safe_literal_eval(x):\n",
    "        try:\n",
    "            return ast.literal_eval(x) if isinstance(x, str) else [np.nan, np.nan, np.nan]\n",
    "        except (ValueError, SyntaxError):\n",
    "            return [np.nan, np.nan, np.nan]\n",
    "    \n",
    "    for dt in dt_list:\n",
    "        if f\"Mat_Time_{dt}\" in df4A.columns and f\"CDS_{dt}\" in df4A.columns:\n",
    "            cds_values = df4A[f'CDS_{dt}'].apply(safe_literal_eval)\n",
    "            mat_time = df4A[f'Mat_Time_{dt}']\n",
    "    \n",
    "            df4A[f'Mat_Matched_CDS_{dt}'] = (\n",
    "                cds_values.apply(lambda x: x[0]) +\n",
    "                mat_time * cds_values.apply(lambda x: x[1]) +\n",
    "                mat_time**2 * cds_values.apply(lambda x: x[2]))\n",
    "    \n",
    "    df4 = df4A[[\"ISIN\",\"CUSIP\",\"Name\",\"Maturity\",\"Issuer Equity_red_tier_ccy_docclause\"] +\\\n",
    "        [col for col in df4A.columns if col.startswith(\"Mat_Matched_CDS\")]].copy()\n",
    "    \n",
    "    ############################################################################################################## NEW BLOCK\n",
    "    \n",
    "    #################################################### Duration Data\n",
    "    \n",
    "    dq_bonds = ['US50077LBF22','US49456BAG68','US49456BAR24','US49456BAV36','US49456BAX91','US500255AX28','US50077LAL09','US50077LAV80','US50077LBN55','US526057CY87','US530715AJ01','US501044DV05','US48666KAY55','US48666KAZ21','US48666KBA60','US620076BT59','US626717AP72','US63938CAN83','US63938CAP32','US63938CAQ15','US651229BD74','US549271AF19','US55262CAJ99','US552676AT59','US552676AU23','US552953CJ87','US552953CK50','US55342UAM62','US55616XAM92','US58013MFQ24','US382550BJ95','US382550BK68','US382550BR12','US382550BS94','US404119CA57','US404119CC14','US404119CK30','US404119CQ00','US404119CT49','US337932AL12','US337932AP26','US345370CA64','US345370CX67','US345370DA55','US345370DB39','US35671DBJ37','US35671DCD57','US35671DCF06','US35671DCH61','US36186CBY84','US36962GXZ26','US370334CL64','US370334CT90','US37045VAH33','US37045VAY65','US37045VAZ31','US404119DB22','US404121AK12','US458140BR09','US651229BE57','US44107TBC99','US40434LAN55','US42307TAG31','US432833AF84','US437076CB65','US44106MAY84','US44106MBB72','US44107TAY29','US44107TAZ93','US651229BF23','US89352HBA68','US893830AF64','US902494AZ66','US911363AM11','US911365BL76','US911365BP80','US91324PEJ75','US911365BN33','US88947EAU47','US85172FAR01','US87264ABF12','US87264ABT16','US87264ABW45','US87264ABX28','US87264ACB98','US87264ACQ67','US87264ACV52','US87264ADT97','US87901JAH86','US88033GAV23','US88167AAR23','US88167AAS06','US88167AAT88','US962166BR41','US963320AY28','US963320AZ92','US963320BA33','US963320BC98','US963320BD71','US963320BE54','US969457BB59','US969457BM15','US969457BZ28','US969457CJ76','US988498AN16','US988498AP63','US988498AR20','XS0161100515','US931142FC22','US92343VEU44','US92343VFX73','US92343VGN82','US92343VGY48','US92343VGZ13','US925524AH30','US925524AV24','US92556HAB33','US92556HAD98','US680665AK27','US682691AA80','US682691AE03','US682691AF77','US682691AG50','US682691AJ99','US682691AK62','US682691AL46','US68389XBV64','US68389XCE31','US68389XCH61','US68389XCJ28','US69047QAC69','US674599EL59','US674599EK76','US65339KCU25','US65339KDJ60','US65339KDK34','US65339KDL17',\n",
    "    'US674599DD43','US674599DE26','US674599EA94','US674599ED34','US674599EF81','US698900AG20','US75513ECR09','US78355HLC15','US78442FAZ18','US81761LAE20','US828807DT11','US716973AD41','US716973AE24','US717081EW90','US745867AM30','US745867AP60','US745867AT82','US74834LBC37','US30212PBH73','US1248EPCN14','US012873AK13','US012873AH83','US11135FAS02','US11135FBD24','US136385AE19','US134429BJ73','US126650DJ69','US00206RMM15','US126650DU15','US126650ED80','US031162DQ06','US026874DC84','US02406PBB58','US023551AM66','US023551AJ38','US097023CN34','US097023CP81','US097023CY98','US097023DC69','US097023DR39','US097023CJ22','US097023DS12','US023135AP19','US097023AU94','US023551AF16','US058498AW66','US058498AX40','US058498BA38','US07556QBT13','US08652BAB53','US071813BY49','US254709AS70','US244199BJ37','US247361ZT81','US251799AA02','US25179MBF95','US25179SAD27','US247361A329','US23331ABT51','US29273VAU44','US29273VBA70','US29278NAQ60','US30161NAX93','US30212PAR64','US29273VAT70','US29273RBE80','US28368EAD85','US28368EAE68','US292480AM22','US29273VAQ32','US292505AD65','US20030NEE76','US20030NDG34','US20030NBH35','US15089QAZ72','US15089QBA13','US15089QAY08','US00206RCP55','US15089QAP90','US00130HCG83','US15089QAX25','US205887AX04','XS2774392638','XS2655993033','XS3037720227','XS3023963534','XS3126635039','XS3106096178','XS3105513769','XS3091660194','XS2872799734','XS2870878456','XS2864439158','XS2811097075','XS2802883731','XS2826718087','XS2929387996','XS2922654418','XS2914769299','XS2904791774','XS2385393587','XS2116386132','XS2432162654','XS2247549731','XS2189766970','XS2300293003','XS2290544068','XS2056491587','XS2488809612','XS2010039894','FR001400WJR8','FR001400PAJ8','DE000A383HC1','CH0494734418','CH0591979627','DE000A4DFLQ6','US46284VAQ41','US501797AW48','US513272AD65','US513272AE49','US53219LAX73','US46284VAN10','US55617LAR33','US55617LAS16','US62482BAB80','US46284VAL53','US44332PAJ03','US46284VAF85','US37441QAA94','US428040DB25','US431318AV64','US431318AY04','US431318AZ78','US431318BC74','US431318BE31','US431318BG88','US432833AL52','US432833AN19','US432833AQ40','US432833AR23','US432833AS06','US44332PAG63','US62886HBP55','US46284VAJ08','US62886HBR12','US629377CS98','US629377CR16','US780153BV38','US780153BW11','US81211KAK60','US812127AB45','US812127AC28','US82967NBG25','US82967NBM92','US853496AG21','US853496AH04','US893830BZ10','US911365BR47','US92840VAP76','US92840VAR33','US947075AU14','US988498AL59','US780153BU54','US75606DAQ43','US737446AV69','US629377CW01','US629377CX83','US62957HAP01','US62957HAQ83','US63861CAF68','US64110LAU08','US64110LAV80','US677347CH71','US680665AN65','US68622FAB76','US68622TAB70','US737446AP91','US737446AQ74','US737446AR57','US737446AX26','US364760AQ18','US11135FBF71','US11135FBH38','US11135FBK66''US11135FBL40','US11135FBT75','US1248EPCD32','US1248EPCE15','US1248EPCK74','US1248EPCL57','US1248EPCP61','US1248EPCQ45''US1248EPCS01','US1248EPCT83','US126307BA42','US126307BB25','US103304BV23','US126307BD80','US097751CD18','US097751CB51','US00130HCC79','US01883LAD55','US01883LAH69','US03743QAQ10','US04433LAA08','US05368VAA44','US05368VAB27','US053773BH95','US053773BJ51','US053773BK25','US071734AJ60','US071734AL17','US097751AL51','US097751CA78','US097751CC35','US126307BF39','US126307BH94','US126307BK24','US224044CS42','US226373AT56','US23918KAS78','US23918KAT51','US23918KAW80','US23918KAY47','US185899AS01','US185899AR28','US12769GAA85','US12769GAD25','US131347CQ78','US143658BX94','US143658BY77','US364760AP35','US143658BZ43','US17888HAB96','US17888HAC79','US17888HAD52','US185899AL57','US185899AN14','US185899AP61','US185899AQ45','US143658CA82']\n",
    "    \n",
    "    dq_bonds = list(df4[\"ISIN\"])\n",
    "    all_labels = dict(zip(df4[\"ISIN\"],[f\"DB(CREDIT,HY,BOND,{item},MDUR)\" for item in df4[\"CUSIP\"]]))\n",
    "    \n",
    "    labels = {}\n",
    "    for item in dq_bonds:\n",
    "        labels[f\"{item}_Dur\"] = all_labels[item]\n",
    "    \n",
    "    try:\n",
    "        if not update_live or data_type != \"Par\":\n",
    "            df1 = pd.read_excel(\"DQ HY Duration Data.xlsx/\",index_col=0, parse_dates=True)\n",
    "        dq = DataQuery(\n",
    "            client_id='jbAIMF2Tkp0JO3sc',\n",
    "            client_secret='d7qfzgt55pddjs352sgxosFyI4t2eja07k7opbi6wg9oqjc1OjkdAksn1btmnugeMjchcx2vwTsJupw',\n",
    "            # calendar = 'CAL_USBANK',\n",
    "        )\n",
    "        \n",
    "        job = dq.create_job(expressions = list(labels.values()))\n",
    "        dq.start_date = str((datetime.now()-timedelta(days=5*365)).date())\n",
    "        job.execute(alert_long_requests='ignore')\n",
    "        df = job.to_pivot_table()\n",
    "        df = df.T\n",
    "        df.index.name = 'Date'\n",
    "        df.index = pd.to_datetime(df.index, format='%Y%m%d').date\n",
    "        df.columns.name = None\n",
    "        \n",
    "        df1 = pd.DataFrame()\n",
    "        for key in labels:\n",
    "            df1[key] = df[labels[key]]\n",
    "        \n",
    "        df1 = df1[list(labels.keys())].copy()\n",
    "        clear_output(wait=False)\n",
    "        df1.dropna(axis=1, how='all', inplace=True)\n",
    "        df1.to_excel(\"DQ HY Duration Data.xlsx\")\n",
    "    except:\n",
    "        df1 = pd.read_excel(\"DQ HY Duration Data.xlsx\",index_col=0, parse_dates=True)\n",
    "    \n",
    "    ############################################################################################################## NEW BLOCK\n",
    "    \n",
    "    df1 = pd.read_excel(\"DQ HY Duration Data.xlsx\",index_col=0, parse_dates=True)\n",
    "    df1a = df1.copy()\n",
    "    df1a = df1a.T\n",
    "    df1a.index = df1a.index.str.replace(\"_Dur\",\"\")\n",
    "    df1a.columns = [\"Dur_\" + str(item.date()) for item in df1a.columns]\n",
    "    df1a.index.name=\"ISIN\"\n",
    "    df1a = df1a.reset_index()\n",
    "    \n",
    "    df4B = pd.merge(left=df4, right=df1a, on=\"ISIN\", how=\"outer\")\n",
    "    \n",
    "    ####################################################################\n",
    "    \n",
    "    t = [f\"/isin/{item}@BGN\" for item in list(all_df[\"ISIN\"])]\n",
    "    if update_live and data_type == \"Par\" :\n",
    "        px = blp.bdh(tickers=t, flds=\"PX_LAST\", start_date=datetime.now()-timedelta(days=365*7))\n",
    "        px.to_parquet(\"BBG PX.parquet\")\n",
    "    px = pd.read_parquet(\"BBG PX.parquet\")\n",
    "    \n",
    "    new = []\n",
    "    for item in px.columns:\n",
    "        new += [item[0].replace(\"/isin/\",\"\").replace(\"@BGN\",\"\")]\n",
    "    px.columns = new\n",
    "    px = px.T\n",
    "    px.columns = [\"Price_\" + str(item) for item in px.columns]\n",
    "    px.index.name= \"ISIN\"\n",
    "    px = px.reset_index()\n",
    "    \n",
    "    ####################################################\n",
    "    df5a = pd.merge(left=df4B, right=bbg1, on=\"ISIN\", how=\"inner\")\n",
    "    last_update = max(dt_list)\n",
    "    for dt in dt_list:\n",
    "        try:\n",
    "            df5a[f\"Basis_{dt}\"] = df5a[f\"Mat_Matched_CDS_{dt}\"] - df5a[f\"Sprd_{dt}\"]\n",
    "        except:\n",
    "            hello = 1\n",
    "    \n",
    "    df5a = pd.merge(left=df5a, right=px, on=\"ISIN\", how=\"inner\")\n",
    "\n",
    "    return df5a.copy()\n",
    "    ############################################################################################################## NEW BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73e39702-b143-44c1-8a89-847a2e625c59",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "par = three_curves(markit_par, global_update_live, \"Par\")\n",
    "uf100 = three_curves(markit_uf100, global_update_live, \"100\")\n",
    "uf100 = uf100[[\"ISIN\"]+[col for col in uf100.columns if col.startswith(\"Mat_Matched_CDS\")]]\n",
    "uf100.columns = uf100.columns.str.replace(\"CDS\",\"UF100\")\n",
    "\n",
    "uf500 = three_curves(markit_uf500, global_update_live, \"500\")\n",
    "uf500 = uf500[[\"ISIN\"]+[col for col in uf500.columns if col.startswith(\"Mat_Matched_CDS\")]]\n",
    "uf500.columns = uf500.columns.str.replace(\"CDS\",\"UF500\")\n",
    "uf = pd.merge(left = uf100, right = uf500, on=\"ISIN\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4631848d-380b-4124-ae23-c0cfaadda18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5a = pd.merge(left = par, right = uf, on=\"ISIN\", how=\"outer\")\n",
    "df5a[[col for col in df5a.columns if \"_UF100_\" in col or \"_UF500_\" in col]] = 100-\\\n",
    "df5a[[col for col in df5a.columns if \"_UF100_\" in col or \"_UF500_\" in col]]\n",
    "\n",
    "for item in dt_list:\n",
    "    if (f\"Price_{item}\" in df5a.columns) and (f\"Mat_Matched_UF100_{item}\" in df5a.columns) and\\\n",
    "    (f\"Mat_Matched_UF500_{item}\" in df5a.columns):\n",
    "        df5a[f\"UF100_Basis_{item}\"] = df5a[f\"Price_{item}\"] - df5a[f\"Mat_Matched_UF100_{item}\"]\n",
    "        df5a[f\"UF500_Basis_{item}\"] = df5a[f\"Price_{item}\"] - df5a[f\"Mat_Matched_UF500_{item}\"]\n",
    "\n",
    "with open('Rating_Dict.json', 'w') as f:\n",
    "    json.dump(f_dict, f)\n",
    "\n",
    "df5a.to_parquet(\"Basis df5a.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
